{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ae49026-c1dd-426a-9647-9b98f8381cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import hashlib\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from moviepy.editor import VideoFileClip\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "raw",
   "id": "257e2ab6-9b05-49ea-ad49-a31882bd0aa2",
   "metadata": {},
   "source": [
    "нужно сбилденый faiss с хедерами и сам TMK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebb604fa-3adc-4b79-bd48-024e6351f826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653e7e50-9d73-4a56-87ea-9edb63ab9b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Первые 5 строк\n",
    "print(data.head())\n",
    "\n",
    "# Информация о датасете\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992473cc-287d-4a84-8fe1-c339fa892938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка на полные дубликаты\n",
    "duplicates = data.duplicated().sum()\n",
    "print(f\"Количество полных дубликатов: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3215fb14-ed01-4dbb-9607-05ca28600c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка на пропущенные значения\n",
    "missing_values = data.isna().sum()\n",
    "print(missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53532ce2-3a28-49dd-8f73-5cd5321117c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка типов данных\n",
    "print(data.dtypes)\n",
    "\n",
    "# Приведение 'created' к типу datetime\n",
    "data[\"created\"] = pd.to_datetime(data[\"created\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3fb4aa-c725-47e3-a1ff-500f6da74d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Распределение целевой переменной\n",
    "\n",
    "\n",
    "sns.countplot(x=\"is_duplicate\", data=data)\n",
    "plt.title(\"Распределение дубликатов\")\n",
    "plt.xlabel(\"Является дубликатом\")\n",
    "plt.ylabel(\"Количество\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc3c49d-94e4-4a16-949f-f7da77f4dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Распределение сложных кейсов\n",
    "sns.countplot(x=\"is_hard\", data=data)\n",
    "plt.title(\"Распределение сложных кейсов\")\n",
    "plt.xlabel(\"Сложный кейс\")\n",
    "plt.ylabel(\"Количество\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d12601-0241-4c63-84e6-821feaca27b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Распределение по времени загрузки\n",
    "data[\"created\"].dt.date.value_counts().sort_index().plot(kind=\"bar\", figsize=(12, 6))\n",
    "plt.title(\"Количество загрузок видео по датам\")\n",
    "plt.xlabel(\"Дата\")\n",
    "plt.ylabel(\"Количество загрузок\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f34ba80-b19d-46b7-a593-cc594e0393e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество дублей для каждого оригинала\n",
    "duplicate_counts = data[data[\"is_duplicate\"]][\"duplicate_for\"].value_counts()\n",
    "plt.figure(figsize=(12, 6))\n",
    "duplicate_counts.plot(kind=\"hist\", bins=30)\n",
    "plt.title(\"Количество дублей на оригинал\")\n",
    "plt.xlabel(\"Количество дублей\")\n",
    "plt.ylabel(\"Количество оригиналов\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cde2d4f-195a-4e1e-b4f5-7d08bbfe3f7d",
   "metadata": {},
   "source": [
    "### md5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92261334-27a6-4ec3-ba82-00f3b5822978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "data = pd.read_csv(\"updated_train_with_embeddings.csv\")\n",
    "\n",
    "# Путь к папке с видеофайлами\n",
    "video_folder = \"train_dataset\"\n",
    "\n",
    "\n",
    "# Функция для получения информации о видео\n",
    "def get_video_info(index, video_uuid):\n",
    "    video_path = os.path.join(video_folder, f\"{video_uuid}.mp4\")  # Предполагаем, что файлы названы по UUID с расширением .mp4\n",
    "    try:\n",
    "        # Проверяем, существует ли файл\n",
    "        if not os.path.exists(video_path):\n",
    "            print(f\"Видео не найдено: {video_path}\")\n",
    "            return index, None, None, None\n",
    "\n",
    "        # Получение длины видео и размера файла\n",
    "        clip = VideoFileClip(video_path)\n",
    "        duration = clip.duration  # Длительность в секундах\n",
    "        size = os.path.getsize(video_path)  # Размер в байтах\n",
    "\n",
    "        # Вычисление MD5\n",
    "        md5_hash = hashlib.md5()\n",
    "        # print(f\"Чтение видео для MD5: {video_path}\")\n",
    "        with open(video_path, \"rb\") as f:\n",
    "            for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "                md5_hash.update(chunk)\n",
    "        md5_value = md5_hash.hexdigest()\n",
    "\n",
    "        return index, duration, size, md5_value\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при обработке {video_path}: {e}\")\n",
    "        return index, None, None, None\n",
    "\n",
    "\n",
    "# Функция для обработки видео с параллелизацией\n",
    "def process_videos_in_parallel(data, max_workers=32):\n",
    "    # Список для хранения результатов\n",
    "    results = []\n",
    "\n",
    "    # Функция для передачи данных в потоки\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Используем tqdm для отображения прогресса\n",
    "        futures = [executor.submit(get_video_info, index, row[\"uuid\"]) for index, row in data.iterrows()]\n",
    "\n",
    "        # tqdm отображает прогресс выполнения\n",
    "        for future in tqdm(futures, desc=\"Processing videos\"):\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "\n",
    "    # Обновление DataFrame с результатами\n",
    "    for result in results:\n",
    "        index, duration, size, md5_value = result\n",
    "        data.at[index, \"duration\"] = duration\n",
    "        data.at[index, \"size\"] = size\n",
    "        data.at[index, \"md5\"] = md5_value\n",
    "\n",
    "\n",
    "# Инициализация новых колонок\n",
    "data[\"duration\"] = None\n",
    "data[\"size\"] = None\n",
    "data[\"md5\"] = None\n",
    "\n",
    "# Обработка видеофайлов параллельно с отображением прогресса\n",
    "process_videos_in_parallel(data, max_workers=32)\n",
    "\n",
    "# Сохранение обновленного DataFrame\n",
    "data.to_csv(\"updated_train_emb_md5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa689e95-32f4-4cc7-898b-d2b0af693d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"updated_train_emb_md5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40fe6db-ab67-4406-b238-b976c6bc22b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ полученных данных\n",
    "\n",
    "# Статистика по длительности видео\n",
    "print(\"Статистика по длительности видео:\")\n",
    "print(data[\"duration\"].describe())\n",
    "\n",
    "# Статистика по размеру файлов\n",
    "print(\"\\nСтатистика по размеру файлов (в байтах):\")\n",
    "print(data[\"size\"].describe())\n",
    "\n",
    "# Анализ на наличие одинаковых MD5\n",
    "duplicate_md5 = data[data.duplicated(subset=\"md5\", keep=False)]\n",
    "print(f\"\\nКоличество файлов с одинаковыми MD5: {len(duplicate_md5)}\")\n",
    "\n",
    "# Вывод всех файлов с одинаковыми MD5\n",
    "if len(duplicate_md5) > 0:\n",
    "    print(\"\\nФайлы с одинаковыми MD5:\")\n",
    "    print(duplicate_md5[[\"uuid\", \"md5\"]])\n",
    "\n",
    "# Визуализация распределения длительности видео\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(data[\"duration\"].dropna(), bins=30, color=\"blue\", alpha=0.7)\n",
    "plt.title(\"Распределение длительности видео\")\n",
    "plt.xlabel(\"Длительность (секунды)\")\n",
    "plt.ylabel(\"Количество видео\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Визуализация распределения размера файлов\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(data[\"size\"].dropna(), bins=30, color=\"green\", alpha=0.7)\n",
    "plt.title(\"Распределение размера файлов\")\n",
    "plt.xlabel(\"Размер файла (байты)\")\n",
    "plt.ylabel(\"Количество видео\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffc0d00-42c8-4415-be7c-1cb7399a7cce",
   "metadata": {},
   "source": [
    "### TMK emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea143ef3-3226-4404-af36-a871b1482bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Путь к папке с видеофайлами\n",
    "video_folder = \"train_dataset\"\n",
    "\n",
    "# Путь к исполняемым файлам TMK и FFmpeg\n",
    "tmk_executable_path = \"/jupyter/ThreatExchange/tmk/cpp\"\n",
    "ffmpeg_path = \"/usr/bin/ffmpeg\"  # Убедитесь, что путь корректен.\n",
    "\n",
    "# Директория для сохранения эмбеддингов\n",
    "embedding_directory = \"/jupyter/emb\"\n",
    "\n",
    "# URL-шаблон для скачивания видео при отсутствии ссылки\n",
    "video_url_template = \"https://s3.ritm.media/yappy-db-duplicates/{uuid}.mp4\"\n",
    "\n",
    "\n",
    "# Функция для загрузки видеофайла по ссылке\n",
    "def download_video(video_url, output_path):\n",
    "    try:\n",
    "        print(f\"Загрузка видео с {video_url} в {output_path}\")\n",
    "\n",
    "        # Отправляем запрос на получение файла\n",
    "        response = requests.get(video_url, stream=True, timeout=60)\n",
    "\n",
    "        # Проверяем статус ответа\n",
    "        if response.status_code == 200:\n",
    "            # Открываем файл для записи\n",
    "            with open(output_path, \"wb\") as f:\n",
    "                for chunk in response.iter_content(1024 * 1024):  # Загружаем по 1 МБ\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "\n",
    "            # Проверяем, действительно ли файл был успешно записан\n",
    "            if os.path.exists(output_path):\n",
    "                print(f\"Видео успешно загружено: {output_path}\")\n",
    "                return output_path\n",
    "            else:\n",
    "                print(f\"Ошибка при сохранении файла: {output_path}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"Ошибка загрузки видео, статус код: {response.status_code} для {video_url}\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке видео {video_url}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Функция для генерации эмбеддингов с использованием TMK\n",
    "def generate_tmk_embedding(video_path):\n",
    "    try:\n",
    "        # Убедитесь, что директория для эмбеддингов существует\n",
    "        if not os.path.exists(embedding_directory):\n",
    "            os.makedirs(embedding_directory)\n",
    "\n",
    "        # Извлекаем имя файла без расширения\n",
    "        video_filename = os.path.basename(video_path)\n",
    "        video_base_name = os.path.splitext(video_filename)[0]  # Получаем имя без .mp4\n",
    "\n",
    "        # Формирование пути к сгенерированному файлу эмбеддинга\n",
    "        tmk_output = os.path.join(embedding_directory, f\"{video_base_name}.tmk\")\n",
    "\n",
    "        # Проверка, существует ли файл эмбеддинга\n",
    "        if os.path.exists(tmk_output):\n",
    "            return tmk_output  # Эмбеддинг уже существует, возвращаем его путь\n",
    "\n",
    "        # Запуск TMK для создания эмбеддинга\n",
    "        subprocess.run(\n",
    "            [os.path.join(tmk_executable_path, \"tmk-hash-video\"), \"-f\", ffmpeg_path, \"-i\", video_path, \"-o\", tmk_output],\n",
    "            check=True,\n",
    "        )\n",
    "\n",
    "        return tmk_output\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Ошибка при генерации эмбеддинга для {video_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Функция для обработки одного видео (загрузка и создание эмбеддинга)\n",
    "def process_video(uuid, video_link, retries=2):\n",
    "    video_path = os.path.join(video_folder, f\"{uuid}.mp4\")\n",
    "\n",
    "    for attempt in range(retries + 1):\n",
    "        # Проверка, существует ли видео\n",
    "        if not os.path.exists(video_path) or attempt > 0:\n",
    "            if attempt > 0:\n",
    "                print(f\"Попытка #{attempt} загрузки {uuid}\")\n",
    "            # Если ссылка отсутствует, используем шаблон для загрузки видео\n",
    "            if not video_link or pd.isna(video_link):\n",
    "                video_link = video_url_template.format(uuid=uuid)\n",
    "            # Если видео не найдено или произошла ошибка, загружаем его по ссылке\n",
    "            video_path = download_video(video_link, video_path)\n",
    "            if video_path is None:\n",
    "                return None  # Пропускаем этот файл, если его не удалось загрузить\n",
    "\n",
    "        # Генерация эмбеддинга для видео\n",
    "        tmk_embedding_path = generate_tmk_embedding(video_path)\n",
    "\n",
    "        if tmk_embedding_path:\n",
    "            return tmk_embedding_path  # Успешно обработали\n",
    "\n",
    "        # Если ошибка, удаляем поврежденное видео и пытаемся снова\n",
    "        if os.path.exists(video_path):\n",
    "            os.remove(video_path)\n",
    "            print(f\"Удалено поврежденное видео: {video_path}\")\n",
    "\n",
    "    return None  # Если все попытки не удались\n",
    "\n",
    "\n",
    "# Функция для обработки основного видео и его дубликата\n",
    "def process_both_videos(index, uuid, video_link, duplicate_uuid, data):\n",
    "    # Обработка основного видео\n",
    "    tmk_embedding_path = process_video(uuid, video_link)\n",
    "    if tmk_embedding_path:\n",
    "        data.at[index, \"tmk_embedding\"] = tmk_embedding_path\n",
    "\n",
    "    # Обработка видео из duplicate_for\n",
    "    if pd.notna(duplicate_uuid) and pd.isna(data.at[index, \"duplicate_tmk_embedding\"]):\n",
    "        # Попробуем получить duplicate_video_link из data\n",
    "        duplicate_row = data[data[\"uuid\"] == duplicate_uuid]\n",
    "        duplicate_video_link = duplicate_row.iloc[0][\"link\"] if not duplicate_row.empty else None\n",
    "\n",
    "        # Обработка duplicate_video_link\n",
    "        duplicate_tmk_embedding_path = process_video(duplicate_uuid, duplicate_video_link)\n",
    "        if duplicate_tmk_embedding_path:\n",
    "            data.at[index, \"duplicate_tmk_embedding\"] = duplicate_tmk_embedding_path\n",
    "        else:\n",
    "            print(f\"Не удалось обработать duplicate_uuid {duplicate_uuid}\")\n",
    "\n",
    "\n",
    "# Основная функция для распараллеливания загрузки и обработки видео\n",
    "def process_videos_in_parallel(data, max_workers=32):\n",
    "    # Инициализация новых столбцов для эмбеддингов, если их еще нет\n",
    "    if \"tmk_embedding\" not in data.columns:\n",
    "        data[\"tmk_embedding\"] = None\n",
    "    if \"duplicate_tmk_embedding\" not in data.columns:\n",
    "        data[\"duplicate_tmk_embedding\"] = None\n",
    "\n",
    "    # Создаем список задач для обработки\n",
    "    tasks = []\n",
    "\n",
    "    # Собираем данные для обработки\n",
    "    for index, row in data.iterrows():\n",
    "        uuid = row[\"uuid\"]\n",
    "        video_link = row.get(\"link\", None)\n",
    "        duplicate_uuid = row.get(\"duplicate_for\", None)\n",
    "\n",
    "        tasks.append((index, uuid, video_link, duplicate_uuid))\n",
    "\n",
    "    # Прогресс бар\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for task in tasks:\n",
    "            index, uuid, video_link, duplicate_uuid = task\n",
    "            futures.append(executor.submit(process_both_videos, index, uuid, video_link, duplicate_uuid, data))\n",
    "\n",
    "        # Обновление прогресс-бара\n",
    "        for future in tqdm(futures, total=len(futures), desc=\"Processing videos\"):\n",
    "            future.result()  # Ожидаем завершения задачи\n",
    "\n",
    "\n",
    "# Запуск параллельной обработки\n",
    "process_videos_in_parallel(data, max_workers=32)\n",
    "\n",
    "# Сохранение обновленного DataFrame с путями к эмбеддингам\n",
    "data.to_csv(\"updated_train_with_embeddings.csv\", index=False)\n",
    "\n",
    "print(\"Генерация TMK-эмбеддингов завершена.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bff8da-52a8-4b40-bcf1-b153b027d9ee",
   "metadata": {},
   "source": [
    "### получаем кластера, ходим кластера 2 и больше, если в кластере больше 2 видео значит они сложные и ставим метку is_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4874c4b9-9794-4022-b65b-7be2e0487ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 1: Запуск команды tmk-clusterize-parallel и парсинг ее вывода\n",
    "def run_tmk_clusterize():\n",
    "    command = \"find /jupyter/dup/emb -name '*.tmk' | \" \"/jupyter/ThreatExchange/tmk/cpp/tmk-clusterize-parallel \" \"-s --min 2 -i\"\n",
    "\n",
    "    # Запуск команды\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True, check=False)\n",
    "\n",
    "    # Получение вывода команды\n",
    "    cluster_output = result.stdout\n",
    "    return cluster_output\n",
    "\n",
    "\n",
    "# Функция для парсинга данных из tmk-clusterize-parallel\n",
    "def parse_tmk_cluster_output(cluster_output):\n",
    "    clusters = {}\n",
    "    for line in cluster_output.strip().splitlines():\n",
    "        match = re.match(r\"clidx=(\\d+),clusz=(\\d+),filename=\\/[a-zA-Z0-9\\/\\.\\-_]+\\/([a-f0-9\\-]+)\\.tmk\", line)\n",
    "        if match:\n",
    "            clidx = int(match.group(1))\n",
    "            uuid = match.group(3)\n",
    "            if clidx not in clusters:\n",
    "                clusters[clidx] = []\n",
    "            clusters[clidx].append(uuid)\n",
    "    # print(\"Распарсенные кластеры:\")\n",
    "    # print(clusters)\n",
    "    return clusters\n",
    "\n",
    "\n",
    "# Шаг 2: Запуск tmk-clusterize-parallel и получение кластеров\n",
    "cluster_output = run_tmk_clusterize()\n",
    "clusters = parse_tmk_cluster_output(cluster_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8137d811-4e98-4076-a7cf-1f46d7cd1ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 3: Чтение DataFrame с данными\n",
    "df = pd.read_csv(\"updated_train_emb_md5.csv\")\n",
    "\n",
    "# Преобразуем колонку 'created' в datetime формат для корректного сравнения\n",
    "df[\"created\"] = pd.to_datetime(df[\"created\"])\n",
    "\n",
    "# Добавляем новые колонки\n",
    "df[\"is_duplicate_tmk\"] = False\n",
    "df[\"duplicate_for_tmk\"] = None\n",
    "df[\"is_hard_tmk\"] = False  # Добавляем колонку для сложных кластеров\n",
    "\n",
    "# Обработка случаев, когда uuid есть в duplicate_for, но отсутствует в uuid\n",
    "# Находим такие uuid и добавляем их в DataFrame\n",
    "duplicate_for_uuids = df[\"duplicate_for\"].dropna().unique()\n",
    "existing_uuids = df[\"uuid\"].unique()\n",
    "missing_uuids = set(duplicate_for_uuids) - set(existing_uuids)\n",
    "\n",
    "# Создаем DataFrame с отсутствующими оригиналами\n",
    "if missing_uuids:\n",
    "    missing_rows = pd.DataFrame({\"uuid\": list(missing_uuids)})\n",
    "    # Заполняем недостающие колонки\n",
    "    missing_rows[\"created\"] = pd.NaT  # Нет данных о дате создания\n",
    "    missing_rows[\"link\"] = None\n",
    "    missing_rows[\"is_duplicate\"] = False\n",
    "    missing_rows[\"duplicate_for\"] = None\n",
    "    missing_rows[\"is_hard\"] = False\n",
    "    # Добавляем в основной DataFrame\n",
    "    df = pd.concat([df, missing_rows], ignore_index=True)\n",
    "\n",
    "# Шаг 4: Заполнение новых колонок на основе кластеров\n",
    "for cluster in clusters.values():\n",
    "    # Отбираем данные по uuid из кластера\n",
    "    cluster_data = df[df[\"uuid\"].isin(cluster)].copy()\n",
    "    # Если есть отсутствующие uuid в df, создадим записи для них\n",
    "    missing_in_df = set(cluster) - set(cluster_data[\"uuid\"])\n",
    "    if missing_in_df:\n",
    "        # Создаем записи для отсутствующих uuid\n",
    "        missing_rows = pd.DataFrame({\"uuid\": list(missing_in_df)})\n",
    "        # Заполняем недостающие колонки\n",
    "        missing_rows[\"created\"] = pd.NaT  # Нет данных о дате создания\n",
    "        missing_rows[\"link\"] = None\n",
    "        missing_rows[\"is_duplicate\"] = False\n",
    "        missing_rows[\"duplicate_for\"] = None\n",
    "        missing_rows[\"is_hard\"] = False\n",
    "        # Добавляем в cluster_data и df\n",
    "        cluster_data = pd.concat([cluster_data, missing_rows], ignore_index=True)\n",
    "        df = pd.concat([df, missing_rows], ignore_index=True)\n",
    "    # Сортируем cluster_data по 'created', NaT будут в конце\n",
    "    cluster_data = cluster_data.sort_values(by=\"created\")\n",
    "    original_uuid = cluster_data.iloc[0][\"uuid\"]  # Самое раннее видео считаем оригиналом\n",
    "    # Если кластер больше двух элементов, ставим метку is_hard_tmk для всех и не проставляем дубликаты\n",
    "    if len(cluster) > 2:\n",
    "        df.loc[df[\"uuid\"].isin(cluster), \"is_hard_tmk\"] = True\n",
    "    else:\n",
    "        # Для кластера из 2 видео проставляем метки дубликатов\n",
    "        for duplicate_uuid in cluster_data[\"uuid\"].tolist()[1:]:\n",
    "            df.loc[df[\"uuid\"] == duplicate_uuid, \"is_duplicate_tmk\"] = True\n",
    "            df.loc[df[\"uuid\"] == duplicate_uuid, \"duplicate_for_tmk\"] = original_uuid\n",
    "\n",
    "# Шаг 5: Проверка корректности заполнения поля duplicate_for_tmk\n",
    "# Убедимся, что все дубликаты имеют корректного оригинала и что для оригиналов поле duplicate_for_tmk не заполнено\n",
    "for cluster in clusters.values():\n",
    "    cluster_data = df[df[\"uuid\"].isin(cluster)].copy()\n",
    "    # Обрабатываем отсутствующие uuid\n",
    "    missing_in_df = set(cluster) - set(cluster_data[\"uuid\"])\n",
    "    if missing_in_df:\n",
    "        # Создаем записи для отсутствующих uuid\n",
    "        missing_rows = pd.DataFrame({\"uuid\": list(missing_in_df)})\n",
    "        # Заполняем недостающие колонки\n",
    "        missing_rows[\"created\"] = pd.NaT\n",
    "        missing_rows[\"link\"] = None\n",
    "        missing_rows[\"is_duplicate\"] = False\n",
    "        missing_rows[\"duplicate_for\"] = None\n",
    "        missing_rows[\"is_hard\"] = False\n",
    "        # Добавляем в cluster_data\n",
    "        cluster_data = pd.concat([cluster_data, missing_rows], ignore_index=True)\n",
    "    # Сортируем cluster_data по 'created', NaT будут в конце\n",
    "    cluster_data = cluster_data.sort_values(by=\"created\")\n",
    "    original_uuid = cluster_data.iloc[0][\"uuid\"]\n",
    "    # Убедимся, что поле duplicate_for_tmk для оригинала пустое\n",
    "    assert pd.isna(\n",
    "        df.loc[df[\"uuid\"] == original_uuid, \"duplicate_for_tmk\"]\n",
    "    ).all(), f\"Ошибка: у оригинала {original_uuid} заполнено поле duplicate_for_tmk\"\n",
    "    # Убедимся, что у всех дубликатов есть ссылка на оригинал, если кластер состоит из двух видео\n",
    "    if len(cluster) == 2:\n",
    "        for duplicate_uuid in cluster_data[\"uuid\"].tolist()[1:]:\n",
    "            duplicate_for = df.loc[df[\"uuid\"] == duplicate_uuid, \"duplicate_for_tmk\"].values[0]\n",
    "            assert (\n",
    "                duplicate_for == original_uuid\n",
    "            ), f\"Ошибка: у дубликата {duplicate_uuid} неверный оригинал {duplicate_for}, должно быть {original_uuid}\"\n",
    "\n",
    "print(\"Проверка заполнения полей завершена успешно.\")\n",
    "\n",
    "# Шаг 6: Корректное сравнение колонок, включая NaN и None\n",
    "df[\"correct\"] = (df[\"is_duplicate\"] == df[\"is_duplicate_tmk\"]) & (\n",
    "    df[\"duplicate_for\"].fillna(\"NaN\") == df[\"duplicate_for_tmk\"].fillna(\"NaN\")\n",
    ")\n",
    "\n",
    "# Шаг 7: Вычисление F1-метрики для поля `duplicate_for` и `duplicate_for_tmk`\n",
    "# Приводим None и NaN к одному виду (например, NaN)\n",
    "df[\"duplicate_for\"] = df[\"duplicate_for\"].fillna(np.nan)\n",
    "df[\"duplicate_for_tmk\"] = df[\"duplicate_for_tmk\"].fillna(np.nan)\n",
    "\n",
    "# Создаем бинарные метки: 1 - duplicate, 0 - not duplicate\n",
    "true_labels = df[\"duplicate_for\"].notna().astype(int)\n",
    "pred_labels = df[\"duplicate_for_tmk\"].notna().astype(int)\n",
    "\n",
    "# Вычисляем F1-метрику\n",
    "f1_duplicate_for = f1_score(true_labels, pred_labels, zero_division=0)\n",
    "\n",
    "# Печать F1 Score для duplicate_for\n",
    "print(f\"F1 score для duplicate_for: {f1_duplicate_for}\")\n",
    "\n",
    "# Шаг 8: Поиск расхождений\n",
    "discrepancies = df[\n",
    "    (df[\"is_duplicate\"] != df[\"is_duplicate_tmk\"]) | (df[\"duplicate_for\"].fillna(\"NaN\") != df[\"duplicate_for_tmk\"].fillna(\"NaN\"))\n",
    "]\n",
    "\n",
    "# Сохранение расхождений для анализа\n",
    "discrepancies.to_csv(\"discrepancies_for_analysis.csv\", index=False)\n",
    "\n",
    "# Сохранение DataFrame с новыми колонками\n",
    "df.to_csv(\"updated_train_with_tmk_duplicates.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8337bc9-d6e0-4f2c-a350-47a30bac43e9",
   "metadata": {},
   "source": [
    "### ищем видосы которые дубли на не нашлись TMK, прогоняем их вручную для теста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d26e94-5f77-4ced-abac-d58cbe75ccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 9: Проверка похожести эмбеддингов с помощью tmk-compare-two-tmks\n",
    "def compare_two_tmks(tmk1_path, tmk2_path):\n",
    "    \"\"\"Функция для сравнения двух .tmk файлов с помощью команды tmk-compare-two-tmks.\n",
    "    Возвращает True, если эмбеддинги похожи, False если нет, и None в случае ошибки.\n",
    "    \"\"\"\n",
    "    command = f\"/jupyter/ThreatExchange/tmk/cpp/tmk-compare-two-tmks {tmk1_path} {tmk2_path}\"\n",
    "    try:\n",
    "        result = subprocess.run(command, shell=True, capture_output=True, text=True, timeout=60, check=False)\n",
    "        output = result.stdout.lower()\n",
    "        if \"similar\" in output:\n",
    "            return True\n",
    "        elif \"not similar\" in output:\n",
    "            return False\n",
    "        else:\n",
    "            return None  # Не удалось определить\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"Команда для сравнения {tmk1_path} и {tmk2_path} превысила время выполнения.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при сравнении {tmk1_path} и {tmk2_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Читаем расхождения из сохранённого файла\n",
    "discrepancies = pd.read_csv(\"discrepancies_for_analysis.csv\")\n",
    "\n",
    "# Фильтруем только те строки, где is_duplicate=True и is_duplicate_tmk=False\n",
    "to_compare = discrepancies[(discrepancies[\"is_duplicate\"] == True) & (discrepancies[\"is_duplicate_tmk\"] == False)].copy()\n",
    "\n",
    "# Построим маппинг uuid -> путь к .tmk файлу\n",
    "# Предполагаем, что все .tmk файлы находятся в /jupyter/dup/emb/ и его поддиректориях\n",
    "tmk_files = glob.glob(\"/jupyter/emb/*.tmk\", recursive=True)\n",
    "uuid_to_path = {}\n",
    "for file in tmk_files:\n",
    "    basename = os.path.basename(file)\n",
    "    uuid = os.path.splitext(basename)[0]\n",
    "    uuid_to_path[uuid] = file\n",
    "\n",
    "# Добавляем столбцы с путями к .tmk файлам\n",
    "to_compare[\"tmk1_path\"] = to_compare[\"uuid\"].map(uuid_to_path)\n",
    "to_compare[\"tmk2_path\"] = to_compare[\"duplicate_for\"].map(uuid_to_path)\n",
    "\n",
    "# Проверяем, что пути найдены\n",
    "missing_tmks = to_compare[to_compare[\"tmk1_path\"].isna() | to_compare[\"tmk2_path\"].isna()]\n",
    "if not missing_tmks.empty:\n",
    "    print(\"Не найдены пути к некоторым .tmk файлам:\")\n",
    "    print(missing_tmks[[\"uuid\", \"duplicate_for\"]])\n",
    "    # Удаляем строки с отсутствующими файлами из дальнейшей обработки\n",
    "    to_compare = to_compare.dropna(subset=[\"tmk1_path\", \"tmk2_path\"])\n",
    "\n",
    "\n",
    "# Функция для сравнения и получения результата\n",
    "def compare_and_record(row):\n",
    "    tmk1 = row[\"tmk1_path\"]\n",
    "    tmk2 = row[\"tmk2_path\"]\n",
    "    similarity = compare_two_tmks(tmk1, tmk2)\n",
    "    return similarity\n",
    "\n",
    "\n",
    "# Применяем функцию ко всем строкам и сохраняем результат\n",
    "to_compare[\"tmk_similarity\"] = to_compare.apply(compare_and_record, axis=1)\n",
    "\n",
    "# Сохраняем результаты сравнения\n",
    "to_compare.to_csv(\"tmk_similarity_results.csv\", index=False)\n",
    "\n",
    "print(\"Проверка похожести эмбеддингов завершена. Результаты сохранены в 'tmk_similarity_results.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da908702-bc9d-4bc8-9939-42ac0839adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43275cc9-f1e5-4859-b9ad-85a4b41be7d6",
   "metadata": {},
   "source": [
    "### команды \n",
    "/jupyter/ThreatExchange/tmk/cpp/tmk-two-level-score-parallel --c1 0.99 --c2 0.0 *.tmk | sort -n\n",
    "\n",
    "find . -name '*.tmk' | /jupyter/ThreatExchange/tmk/cpp/tmk-clusterize-parallel -s --min 2 -i\n",
    "\n",
    "/jupyter/ThreatExchange/tmk/cpp/tmk-compare-two-tmks misc-shelf-sd.tmk misc-shelf-sd.tmk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dccdc2-2e82-430c-8bc2-50e50f4a4041",
   "metadata": {},
   "source": [
    "### отображение 2 видосов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a23a0c-6ff0-48b4-b229-d4c7f6245e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Активация nest-asyncio для работы с асинхронными вызовами в Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Загрузка DataFrame 'to_compare'\n",
    "to_compare = pd.read_csv(\"tmk_similarity_results.csv\")\n",
    "\n",
    "# Инициализация текущего индекса\n",
    "current_index = 0\n",
    "\n",
    "# Создание основного контейнера для кнопок и видео\n",
    "output = widgets.Output()\n",
    "\n",
    "\n",
    "# Асинхронная функция для отображения пар видео и кнопок\n",
    "async def display_video_pair(idx):\n",
    "    with output:\n",
    "        output.clear_output(wait=True)  # Очищаем вывод для обновления\n",
    "\n",
    "        if idx < 0 or idx >= len(to_compare):\n",
    "            display(HTML(\"<p>Индекс вне диапазона.</p>\"))\n",
    "            return\n",
    "\n",
    "        row = to_compare.iloc[idx]\n",
    "        uuid = row[\"uuid\"]\n",
    "        duplicate_for = row[\"duplicate_for\"]\n",
    "\n",
    "        video1_path = f\"train_dataset/{uuid}.mp4\"\n",
    "        video2_path = f\"train_dataset/{duplicate_for}.mp4\"\n",
    "\n",
    "        # Проверка существования видеофайлов\n",
    "        video1_exists = os.path.exists(video1_path)\n",
    "        video2_exists = os.path.exists(video2_path)\n",
    "\n",
    "        if not video1_exists or not video2_exists:\n",
    "            missing = []\n",
    "            if not video1_exists:\n",
    "                missing.append(f\"Оригинал: {uuid}.mp4\")\n",
    "            if not video2_exists:\n",
    "                missing.append(f\"Дубликат: {duplicate_for}.mp4\")\n",
    "            missing_str = \", \".join(missing)\n",
    "            display(HTML(f\"<p style='color:red;'>Видео не найдены: {missing_str}</p>\"))\n",
    "            return\n",
    "\n",
    "        # Получение информации о дубликате\n",
    "        is_duplicate = row.get(\"is_duplicate\", \"N/A\")\n",
    "        is_duplicate_tmk = row.get(\"is_duplicate_tmk\", \"N/A\")\n",
    "        tmk_similarity = row.get(\"tmk_similarity\", \"N/A\")\n",
    "\n",
    "        # HTML-код для отображения видео бок о бок с дополнительной информацией\n",
    "        html_code = f\"\"\"\n",
    "        <div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "            <div style=\"text-align: center;\">\n",
    "                <video width=\"400\" controls>\n",
    "                    <source src=\"{video1_path}\" type=\"video/mp4\">\n",
    "                    Ваш браузер не поддерживает тег video.\n",
    "                </video>\n",
    "                <p><strong>UUID:</strong> {uuid}</p>\n",
    "                <p><strong>is_duplicate:</strong> {is_duplicate}</p>\n",
    "                <p><strong>is_duplicate_tmk:</strong> {is_duplicate_tmk}</p>\n",
    "            </div>\n",
    "            <div style=\"text-align: center;\">\n",
    "                <video width=\"400\" controls>\n",
    "                    <source src=\"{video2_path}\" type=\"video/mp4\">\n",
    "                    Ваш браузер не поддерживает тег video.\n",
    "                </video>\n",
    "                <p><strong>duplicate_for:</strong> {duplicate_for}</p>\n",
    "                <p><strong>tmk_similarity:</strong> {tmk_similarity}</p>\n",
    "            </div>\n",
    "        </div>\n",
    "        <div style=\"text-align: center; margin-top: 20px;\">\n",
    "            <p>Пара: {idx + 1} из {len(to_compare)}</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(html_code))\n",
    "\n",
    "    # Создание кнопок\n",
    "    previous_button = widgets.Button(description=\"⟵ Предыдущий\", button_style=\"info\")\n",
    "    next_button = widgets.Button(description=\"Следующий ⟶\", button_style=\"info\")\n",
    "\n",
    "    # Асинхронные обработчики нажатий кнопок\n",
    "    async def on_previous_clicked(b):\n",
    "        global current_index\n",
    "        if current_index > 0:\n",
    "            current_index -= 1\n",
    "            await display_video_pair(current_index)\n",
    "\n",
    "    async def on_next_clicked(b):\n",
    "        global current_index\n",
    "        if current_index < len(to_compare) - 1:\n",
    "            current_index += 1\n",
    "            await display_video_pair(current_index)\n",
    "\n",
    "    # Привязка функций к кнопкам через асинхронную обработку\n",
    "    previous_button.on_click(lambda b: asyncio.ensure_future(on_previous_clicked(b)))\n",
    "    next_button.on_click(lambda b: asyncio.ensure_future(on_next_clicked(b)))\n",
    "\n",
    "    # Создание контейнера для кнопок\n",
    "    button_box = widgets.HBox([previous_button, next_button])\n",
    "\n",
    "    # Отображение кнопок и видео\n",
    "    display(button_box)\n",
    "\n",
    "\n",
    "# Отображение контейнера для кнопок и видео\n",
    "display(output)\n",
    "\n",
    "# Отображение первой пары видео\n",
    "await display_video_pair(current_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced294b-ec98-4941-b192-f154b84b9ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Активация nest-asyncio для работы с асинхронными вызовами в Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Загрузка DataFrame 'to_compare'\n",
    "to_compare = pd.read_csv(\"tmk_similarity_results.csv\")\n",
    "\n",
    "# Инициализация текущего индекса\n",
    "current_index = 0\n",
    "\n",
    "# Основной контейнер для отображения видео\n",
    "video_output = widgets.Output()\n",
    "\n",
    "# Создание кнопок\n",
    "previous_button = widgets.Button(description=\"⟵ Предыдущий\", button_style=\"info\")\n",
    "next_button = widgets.Button(description=\"Следующий ⟶\", button_style=\"info\")\n",
    "\n",
    "\n",
    "# Функция для отображения видео и кнопок в HTML\n",
    "def generate_html_video_pair(idx):\n",
    "    # Получаем данные для текущей пары видео\n",
    "    row = to_compare.iloc[idx]\n",
    "    uuid = row[\"uuid\"]\n",
    "    duplicate_for = row[\"duplicate_for\"]\n",
    "\n",
    "    video1_path = f\"train_dataset/{uuid}.mp4\"\n",
    "    video2_path = f\"train_dataset/{duplicate_for}.mp4\"\n",
    "\n",
    "    # Проверка существования файлов\n",
    "    video1_exists = os.path.exists(video1_path)\n",
    "    video2_exists = os.path.exists(video2_path)\n",
    "\n",
    "    if not video1_exists or not video2_exists:\n",
    "        missing = []\n",
    "        if not video1_exists:\n",
    "            missing.append(f\"Оригинал: {uuid}.mp4\")\n",
    "        if not video2_exists:\n",
    "            missing.append(f\"Дубликат: {duplicate_for}.mp4\")\n",
    "        missing_str = \", \".join(missing)\n",
    "        return f\"<p style='color:red;'>Видео не найдены: {missing_str}</p>\"\n",
    "\n",
    "    # Получаем дополнительные данные\n",
    "    is_duplicate = row.get(\"is_duplicate\", \"N/A\")\n",
    "    is_duplicate_tmk = row.get(\"is_duplicate_tmk\", \"N/A\")\n",
    "    tmk_similarity = row.get(\"tmk_similarity\", \"N/A\")\n",
    "\n",
    "    # HTML для видео\n",
    "    html_code = f\"\"\"\n",
    "    <div style=\"text-align: center;\">\n",
    "        <div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "            <div>\n",
    "                <video width=\"400\" controls>\n",
    "                    <source src=\"{video1_path}\" type=\"video/mp4\">\n",
    "                    Ваш браузер не поддерживает тег video.\n",
    "                </video>\n",
    "                <p><strong>UUID:</strong> {uuid}</p>\n",
    "                <p><strong>is_duplicate:</strong> {is_duplicate}</p>\n",
    "                <p><strong>is_duplicate_tmk:</strong> {is_duplicate_tmk}</p>\n",
    "            </div>\n",
    "            <div>\n",
    "                <video width=\"400\" controls>\n",
    "                    <source src=\"{video2_path}\" type=\"video/mp4\">\n",
    "                    Ваш браузер не поддерживает тег video.\n",
    "                </video>\n",
    "                <p><strong>duplicate_for:</strong> {duplicate_for}</p>\n",
    "                <p><strong>tmk_similarity:</strong> {tmk_similarity}</p>\n",
    "            </div>\n",
    "        </div>\n",
    "        <p>Пара: {idx + 1} из {len(to_compare)}</p>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    return html_code\n",
    "\n",
    "\n",
    "# Функция для обновления содержимого видео\n",
    "def update_video_output(idx):\n",
    "    with video_output:\n",
    "        video_output.clear_output(wait=True)  # Очищаем вывод\n",
    "        html_code = generate_html_video_pair(idx)  # Генерируем новый HTML\n",
    "        display(HTML(html_code))  # Выводим новый HTML-код\n",
    "\n",
    "\n",
    "# Функции для обработки переходов\n",
    "def on_previous_clicked(b):\n",
    "    global current_index\n",
    "    if current_index > 0:\n",
    "        current_index -= 1\n",
    "        update_video_output(current_index)\n",
    "\n",
    "\n",
    "def on_next_clicked(b):\n",
    "    global current_index\n",
    "    if current_index < len(to_compare) - 1:\n",
    "        current_index += 1\n",
    "        update_video_output(current_index)\n",
    "\n",
    "\n",
    "# Привязка обработчиков к кнопкам\n",
    "previous_button.on_click(on_previous_clicked)\n",
    "next_button.on_click(on_next_clicked)\n",
    "\n",
    "# Инициализация интерфейса кнопок\n",
    "button_box = widgets.HBox([previous_button, next_button])\n",
    "\n",
    "# Отображение кнопок и видео\n",
    "display(button_box)  # Отображаем кнопки\n",
    "display(video_output)  # Отображаем контейнер для видео\n",
    "\n",
    "# Инициализация отображения первой пары видео\n",
    "update_video_output(current_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95fffb8-3b9d-4ed4-ad0f-9040b64c2810",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
